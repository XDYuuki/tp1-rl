# ğŸš– Reinforcement Learning no Ambiente Taxi-v3

Este projeto apresenta uma abordagem de **Aprendizado por ReforÃ§o (Reinforcement Learning)** para resolver o ambiente **Taxi-v3** do Gym utilizando o algoritmo **ProgramaÃ§Ã£o DinÃ¢mica**. O problema Ã© modelado como um **Processo de DecisÃ£o de Markov (MDP)** e resolvido com um mÃ©todo tabular.

> Trabalho desenvolvido para a disciplina _IntroduÃ§Ã£o ao Aprendizado por ReforÃ§o_ â€” 2025.

---

## ğŸ“Œ Objetivo

Modelar o ambiente **Taxi-v3** como um MDP e aplicar **P.D.** para aprender uma polÃ­tica Ã³tima. O resultado Ã© avaliado com base na funÃ§Ã£o valor, funÃ§Ã£o valor-aÃ§Ã£o e desempenho do agente.

---


---

## ğŸ§® MÃ©todo: IteraÃ§Ã£o de Valores

A **iteraÃ§Ã£o de valores** resolve o MDP ao atualizar a funÃ§Ã£o valor atÃ© a convergÃªncia:

$$
V_{k+1}(s) = \max_a \sum_{s', r} P(s', r \mid s, a) \left[ r + \gamma V_k(s') \right]
$$

Onde:

- \( V_k(s) \) Ã© a estimativa da funÃ§Ã£o valor no passo \( k \),
- \( \gamma \) Ã© o fator de desconto,
- \( P(s', r \mid s, a) \) Ã© a probabilidade de transiÃ§Ã£o,
- \( r \) Ã© a recompensa recebida na transiÃ§Ã£o de \( s \) para \( s' \) apÃ³s a aÃ§Ã£o \( a \).

---

## ğŸ“Š Resultados

### ğŸ“ˆ ConvergÃªncia da FunÃ§Ã£o Valor
![FunÃ§Ã£o Valor](evolucao_recompensa.png)

---

### ğŸ§­ PolÃ­tica Ã“tima Derivada
![PolÃ­tica Ã“tima](convergencia_policy_evaluation.png)

---


## âš™ï¸ Como Executar

1. Clone o repositÃ³rio:
   ```bash
   git clone https://github.com/seu-usuario/taxi-v3-dp.git
   cd taxi-v3-dp
2. Instale as dependÃªncias
   ```bash
   pip install -r requirements.txt
3. Rode o Jupyter notebook
   ```bash
   jupyter notebook tp_1.ipynb
